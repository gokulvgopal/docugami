{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gokul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import contractions\n",
    "import string\n",
    "import collections\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = ET.parse('mendeley_document_library_2020-03-25.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove the HTML tag with abstract\n",
    "import re\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the necessary fields from the xml file to a data frame\n",
    "\n",
    "columns=['abstract', 'ref-type', 'title', 'secondary_title', 'full_title', 'year', 'label', 'keyword']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "record_dict = dict()\n",
    "for record in records[0].findall('record'):\n",
    "    try:\n",
    "        record_dict['abstract'] = remove_tags(record.findall('./abstract')[0].text)\n",
    "    except:\n",
    "        record_dict['abstract'] = None\n",
    "    try:\n",
    "        record_dict['ref-type'] = record.findall('./ref-type')[0].attrib.get('name')\n",
    "    except:\n",
    "        record_dict['ref-type'] = None\n",
    "    try:\n",
    "        record_dict['title'] = record.findall('./titles')[0].find('title').text\n",
    "    except:\n",
    "        record_dict['title'] = None\n",
    "    try:\n",
    "        record_dict['secondary_title'] = record.findall('./titles')[0].find('./secondary-title').text\n",
    "    except:\n",
    "        record_dict['secondary_title'] = None\n",
    "    try:\n",
    "        record_dict['full_title'] = record.findall('./periodical')[0].find('./full-title').text\n",
    "    except:\n",
    "        record_dict['full_title'] = None\n",
    "    try:\n",
    "        record_dict['year'] = record.findall('./dates')[0].find('./year').text\n",
    "    except:\n",
    "        record_dict['year'] = None\n",
    "    try:\n",
    "        record_dict['label'] = record.findall('label')[0].text.replace(\";\", \" \")\n",
    "    except:\n",
    "        record_dict['label'] = None\n",
    "    kywrd = ''\n",
    "    for keyword in record.find('./keywords'):\n",
    "        kywrd= kywrd + \" \"+keyword.text\n",
    "    record_dict['keyword'] = kywrd\n",
    "    #print(record_dict)\n",
    "    df = df.append(record_dict, ignore_index=True)\n",
    "    #print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1061, 8)\n"
     ]
    }
   ],
   "source": [
    "# checking the data frame\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>ref-type</th>\n",
       "      <th>title</th>\n",
       "      <th>secondary_title</th>\n",
       "      <th>full_title</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Calling all coronavirus researchers: keep shar...</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Nature</td>\n",
       "      <td>2020</td>\n",
       "      <td>coronavirus reviewed</td>\n",
       "      <td>Genomics Health care Infection Virology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Background : The current novel coronavirus ou...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>The transmissibility of novel Coronavirus in t...</td>\n",
       "      <td>Wellcome Open Research</td>\n",
       "      <td>Wellcome Open Research</td>\n",
       "      <td>2020</td>\n",
       "      <td>coronavirus reviewed</td>\n",
       "      <td>coronavirus modelling outbreak transmission w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The outbreak of the coronavirus disease 2019 (...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Development of CRISPR as a prophylactic strate...</td>\n",
       "      <td>bioRxiv</td>\n",
       "      <td>bioRxiv</td>\n",
       "      <td>2020</td>\n",
       "      <td>biorxiv coronavirus not added reviewed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Background: on the late December 2019, a new e...</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Design of multi epitope-based peptide vaccine ...</td>\n",
       "      <td>bioRxiv</td>\n",
       "      <td>bioRxiv</td>\n",
       "      <td>2020</td>\n",
       "      <td>biorxiv coronavirus reviewed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>A Literature Review of 2019 Novel Coronavirus ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "      <td>coronavirus reviewed</td>\n",
       "      <td>2019-nCoV causes epidemiology prevention and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract         ref-type  \\\n",
       "0                                               None  Journal Article   \n",
       "1   Background : The current novel coronavirus ou...  Journal Article   \n",
       "2  The outbreak of the coronavirus disease 2019 (...  Journal Article   \n",
       "3  Background: on the late December 2019, a new e...  Journal Article   \n",
       "4                                               None  Journal Article   \n",
       "\n",
       "                                               title         secondary_title  \\\n",
       "0  Calling all coronavirus researchers: keep shar...                  Nature   \n",
       "1  The transmissibility of novel Coronavirus in t...  Wellcome Open Research   \n",
       "2  Development of CRISPR as a prophylactic strate...                 bioRxiv   \n",
       "3  Design of multi epitope-based peptide vaccine ...                 bioRxiv   \n",
       "4  A Literature Review of 2019 Novel Coronavirus ...                    None   \n",
       "\n",
       "               full_title  year                                   label  \\\n",
       "0                  Nature  2020                    coronavirus reviewed   \n",
       "1  Wellcome Open Research  2020                    coronavirus reviewed   \n",
       "2                 bioRxiv  2020  biorxiv coronavirus not added reviewed   \n",
       "3                 bioRxiv  2020            biorxiv coronavirus reviewed   \n",
       "4                    None  2020                    coronavirus reviewed   \n",
       "\n",
       "                                             keyword  \n",
       "0            Genomics Health care Infection Virology  \n",
       "1   coronavirus modelling outbreak transmission w...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4   2019-nCoV causes epidemiology prevention and ...  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1061 entries, 0 to 1060\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   abstract         851 non-null    object\n",
      " 1   ref-type         1061 non-null   object\n",
      " 2   title            1061 non-null   object\n",
      " 3   secondary_title  1013 non-null   object\n",
      " 4   full_title       1013 non-null   object\n",
      " 5   year             1042 non-null   object\n",
      " 6   label            1049 non-null   object\n",
      " 7   keyword          1061 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 66.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# data frame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since dealing with documents with little informations is tricky, I'm\n",
    "# leaving out documents with null abstract\n",
    "df_nabs = df[df.abstract.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 851 entries, 1 to 1060\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   abstract         851 non-null    object\n",
      " 1   ref-type         851 non-null    object\n",
      " 2   title            851 non-null    object\n",
      " 3   secondary_title  819 non-null    object\n",
      " 4   full_title       819 non-null    object\n",
      " 5   year             843 non-null    object\n",
      " 6   label            839 non-null    object\n",
      " 7   keyword          851 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 59.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_nabs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Expanding compressed english word combo\n",
    "df_nabs['abstract'] = df_nabs['abstract'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "\n",
    "# Combining the list of words back \n",
    "df_nabs['abstract']= df_nabs['abstract'].apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     [background, the, current, novel, coronavirus,...\n",
       "2     [the, outbreak, of, the, coronavirus, disease,...\n",
       "3     [background, on, the, late, december, 2019, a,...\n",
       "5     [global, airline, networks, play, a, key, role...\n",
       "6     [the, beginning, of, 2020, has, seen, the, eme...\n",
       "7     [the, beginning, of, 2020, has, seen, the, eme...\n",
       "9     [covid, 19, caused, by, a, novel, coronavirus,...\n",
       "10    [summary, objective, to, describe, the, epidem...\n",
       "11    [as, of, 8am, 30th, january, beijing, time, 20...\n",
       "12    [the, outbreak, of, pneumonia, caused, by, a, ...\n",
       "14    [in, december, 2019, a, novel, coronavirus, ca...\n",
       "16    [background, recent, epidemic, of, novel, coro...\n",
       "17    [40, days, after, the, start, of, the, interna...\n",
       "18    [two, months, after, it, was, firstly, reporte...\n",
       "19    [our, society, is, currently, experiencing, an...\n",
       "20    [as, the, coronavirus, covid, 19, expands, its...\n",
       "22    [on, 31, december, 2019, a, cluster, of, 27, p...\n",
       "24    [since, the, first, suspected, case, of, novel...\n",
       "27    [the, impact, of, the, drastic, reduction, in,...\n",
       "28    [the, impact, of, the, drastic, reduction, in,...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize each abstract\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df_nabs['abstract'] = df_nabs['abstract'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df_nabs.head(20).abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     [current, appears, originated, point, source, ...\n",
       "2     [2019, 19, caused, severe, acute, respiratory,...\n",
       "3     [late, december, 2019, new, endemic, spread, a...\n",
       "5     [global, airline, networks, play, key, role, g...\n",
       "6     [beginning, 2020, seen, emergence, 19, caused,...\n",
       "7     [beginning, 2020, seen, emergence, 19, caused,...\n",
       "9     [19, caused, sars, 2, emerged, wuhan, hubei, p...\n",
       "10    [summary, objective, describe, epidemiological...\n",
       "11    [8am, 30th, january, beijing, 2020, approximat...\n",
       "12    [pneumonia, caused, 2019, ncov, wuhan, city, c...\n",
       "14    [december, 2019, called, 19, discovered, wuhan...\n",
       "16    [recent, epidemic, sars, 2, triggered, rising,...\n",
       "17    [40, days, start, international, monitoring, 1...\n",
       "18    [two, months, firstly, reported, 19, already, ...\n",
       "19    [society, currently, experiencing, unprecedent...\n",
       "20    [19, expands, impact, china, expanding, catchm...\n",
       "22    [31, december, 2019, cluster, 27, pneumonia, c...\n",
       "24    [since, first, suspected, case, 2019, ncov, in...\n",
       "27    [impact, drastic, reduction, travel, volume, w...\n",
       "28    [impact, drastic, reduction, travel, volume, w...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punctuation and stop words are removed from the abstracts\n",
    "df_nabs['abstract'] = df_nabs['abstract'].apply(lambda x: [word for word in x if word not in string.punctuation])\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_nabs['abstract'] = df_nabs['abstract'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_nabs['abstract'] = df_nabs['abstract'].apply(lambda x: [word for word in x if word not in ['coronavirus','outbreak', 'background','novel', 'covid', 'cov','time', 'disease']])\n",
    "df_nabs['abstract'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     current appears originated point source exposu...\n",
       "2     2019 19 caused severe acute respiratory syndro...\n",
       "3     late december 2019 new endemic spread across w...\n",
       "5     global airline network play key role global im...\n",
       "6     beginning 2020 seen emergence 19 caused severe...\n",
       "7     beginning 2020 seen emergence 19 caused severe...\n",
       "9     19 caused sars 2 emerged wuhan hubei province ...\n",
       "10    summary objective describe epidemiological cli...\n",
       "11    8am 30th january beijing 2020 approximate 8000...\n",
       "12    pneumonia caused 2019 ncov wuhan city china ob...\n",
       "14    december 2019 called 19 discovered wuhan china...\n",
       "16    recent epidemic sars 2 triggered rising global...\n",
       "17    40 day start international monitoring 19 searc...\n",
       "18    two month firstly reported 19 already spread w...\n",
       "19    society currently experiencing unprecedented c...\n",
       "20    19 expands impact china expanding catchment su...\n",
       "22    31 december 2019 cluster 27 pneumonia case unk...\n",
       "24    since first suspected case 2019 ncov infected ...\n",
       "27    impact drastic reduction travel volume within ...\n",
       "28    impact drastic reduction travel volume within ...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatizing the words \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "df_nabs['abstract'] = df_nabs['abstract'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x]).apply(lambda x: ' '.join(map(str, x)))\n",
    "df_nabs['abstract'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting abstracts to matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, ngram_range=(1,3))\n",
    "X = vectorizer.fit_transform(df_nabs.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "       n_clusters=5, n_init=1, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification using KMeans\n",
    "number_of_clusters = 5\n",
    "model = KMeans(n_clusters=number_of_clusters, init='k-means++', max_iter=100, n_init=1)\n",
    "\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " number\n",
      " transmission\n",
      " health\n",
      " province\n",
      " science\n",
      " epidemic\n",
      " wuhan\n",
      " statement author\n",
      " 2020\n",
      " competing funding\n",
      "Cluster 1:\n",
      " ncov\n",
      " 2019 ncov\n",
      " wuhan\n",
      " virus\n",
      " sars\n",
      " infection\n",
      " pneumonia\n",
      " transmission\n",
      " health\n",
      " respiratory\n",
      "Cluster 2:\n",
      " sars\n",
      " virus\n",
      " respiratory\n",
      " infection\n",
      " severe\n",
      " result\n",
      " method\n",
      " analysis\n",
      " based\n",
      " infected\n",
      "Cluster 3:\n",
      " severe\n",
      " pneumonia\n",
      " wuhan\n",
      " day\n",
      " result\n",
      " finding\n",
      " method\n",
      " confirmed\n",
      " 2020\n",
      " science\n",
      "Cluster 4:\n",
      " model\n",
      " epidemic\n",
      " number\n",
      " based\n",
      " infected\n",
      " 2020\n",
      " infection\n",
      " spread\n",
      " rate\n",
      " virus\n"
     ]
    }
   ],
   "source": [
    "#Printing out the clusters/ classifications\n",
    "for i in range(number_of_clusters):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
